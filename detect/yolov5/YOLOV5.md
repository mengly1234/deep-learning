# yolov5的主要结构

骨干网络（Backbone）：CSP-Darknet53  
颈部网络（neck）：SPPF, CSP-PAN  
头部网络（head）

## 图像预处理部分

### Mosaic 数据增强 ：

将四张图像拼接到一起，形成一张图像，增加数据的多样性。先随机抽取四张图像，并按照等比列将最大边缩放到指定的size（一般是640），然后将四张图像拼接成一个（2*size）*（2*size）的一张图，最后再缩放到指定size。 


### 自适应锚框计算：

由于数据集不同，yolov5给的锚框不一定适合自己的数据集，所以这个时候可以启动自动锚框计算功能，它通过获取数据集中所有目标的宽和高，然后只要通过k-means的方法进行聚类，来计算合适的锚框大小。

### letterbox：

一般在图像预处理的阶段，使用resize函数将图像统一缩放到一个指定的大小，通常原始图像不是正方形的，但是网络的输入一般都是正方形的，直接进行resize则会将图像拉伸变形，yolov5的自适应缩放是先将图像按照等比列的方式缩放，将图像的最大边缩放到指定的size，使用指定像素填充短边，使其达到指定size。

注：指定的size必须要满足32的倍数，因为yolov5需要进行五次下采样。

## 训练

### 训练相关的参数

	# rect：矩形训练，默认关闭,加了default =True，就是表示图片为1184*1920，
	# resume：断点续训，如果训练过程中意外断掉，或者是想接着训练，就可以使用该参数
	# noautoanchor：关闭自动计算锚框功能，默认关闭
	# noplots：不保存可视化文件
	# evolve：使用超参数优化算法进行自动调参，默认关闭
	# cache：缓存数据集，以加快训练速度
	# image-weights: 对于那些训练不好的图片，会在下一轮中增加一些权重
	# multi - scale: 是否进行多尺度训练，一般设置几种不同尺度的图片，训练时每隔一定iterations随机选取一种尺度训练
	# single-cls: 数据集是否只有一个类别，默认False
	# cos-lr：用于对学习速率进行调整，默认为 False，（通过余弦函数来降低学习率）
	# label-smoothing: 对标签进行平滑处理,防止过拟合

### 网络的结构

### 头部

#### 标签分配：

1、跨anchor检测

具体的做法是将真实的标签复制三份，分别去和三层anchor计算宽高比，ratio1= 真实标签的宽高/anchor宽高，ratio2 = anchor宽高/真实标签的宽高，然后取两者中的最大值和设定阈值进行比较，如果比值太大的话，说明目标不适合用这个anchor进行检测，这一步是为了匹配合适的anchor。

2、跨grid检测

在经过跨anchor检测之后，可以匹配到合适的anchor，那么此时，这个真实的标签一定落在了某个grid内，这个grid有左，上，右，下四个邻域的grid，然后根据真是标签的中心位置，将离的更近的两个邻域grid也作为预测网格，也就是一个真实的标签（即一个目标对象）可以由三个grid预测，这是为了解决，目标太大跨grid的问题。

3、跨分支预测：

假设一个GT框可以和2个甚至3个预测分支上的anchor匹配，则这2个或3个预测分支都可以预测该GT框。即一个GT框可以在3个预测分支上匹配正样本，在每一个分支上重复anchor匹配和grid匹配的步骤，最终可以得到某个GT 匹配到的所有正样本。

#### 损失：
1、分类损失：BCE
2、bounding box的损失：  
（1）IOU_Loss：预测框与GT框之间的交集/预测框与GT框之间的并集  
（2）GIOU_loss：引入最小外接矩形。1-（IOU-(最小外接矩形的面积-预测框与GT框之间的并集)/最小外接矩形的面积）   
（3）NMS非极大值抑制：  
   a）对所有预测框的置信度降序排序  
   b）选出置信度最高的预测框，确认其为正确预测，并计算他与其他预测框的IOU   
   c)IOU>threshold阈值就直接删除
   d)返回步骤a

## 推理时的相关参数

	# conf-thres：检测时置信度阈值，低于这个置信度阈值的直接被筛除
	# iou-thres：iou阈值，当预测框与真实框的重合度大于这个阈值是才被认为是正样本
	# max-det：设置一张图像中的最大检测数量，默认是最多检测 1000 个目标
	# view-img：是否在检测的过程中展示检测的结果
	# save-txt：是否把检测结果保存成一个.txt的格式，txt文件里面保存了一些类别信息和边框的坐标信息。
	# save-conf：以.txt的格式保存目标的置信度，一般配合 - -save - txt一起使用
	# save-crop：是否把模型检测的物体裁剪下来。裁剪的物体图片会保存在crops目录下。
	# nosave：不保存预测的结果。
	# classes：检测的类别，可以设置一个或者多个类别，根据自己的类别名去设置。比如coco数据集里面0，代表person。
	# agnostic-nms：跨类别nms，比如待检测图像中有一个长得很像篮球的足球，pt文件的分类中有足球和篮球两种，那在识别时这个足球可能会被同时框上2个框：一个是足球，一个是篮球。开启agnostic-nms后，那只会框出一个框。
	# augment：推理的时候是否开启图像增强
	# visualize：特征图可视化，开启之后，可以将每层的可视化已图片的形式保存下来
	# update：在模型训练的最后阶段去除优化器信息，以减小模型文件的大小，并将模型准备好用于推断或其他目的。

